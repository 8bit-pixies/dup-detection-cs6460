{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\gensim-0.13.3-py2.7-win-amd64.egg\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\gensim-0.13.3-py2.7-win-amd64.egg\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, make_scorer, confusion_matrix, precision_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from create_dictionary import train_corpus, transform_doc2bow, tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from online_lsi_sim import sim_two_lsi, sim_all_lsi\n",
    "from online_lda_sim import sim_two_lda, sim_all_lda\n",
    "from word2vec_sim import sim_two_w2v, sim_all_w2v\n",
    "from doc_sim import sim_two, sim_all\n",
    "\n",
    "from create_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lda...\n",
      "training lsi...\n",
      "training word2vec...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "227101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dictionary = gensim.corpora.Dictionary.load(\"../data/SESE.gz\")\n",
    "fname = \"../SESE/cleaned/sql-html-sample.csv\"\n",
    "\n",
    "so_dat = pd.read_csv(fname)\n",
    "so_dat_main = so_dat[['id', 'title', 'bodyString', 'tagsString']]\n",
    "\n",
    "label_dat = pd.read_csv(\"../SESE/labels/sql-html-js-2_labels.csv\")\n",
    "\n",
    "\n",
    "# build each feature, and model\n",
    "corpus = train_corpus(so_dat_main['bodyString'].tolist(), dictionary)\n",
    "\n",
    "# all these models have online learning support\n",
    "print \"training lda...\"\n",
    "lda_mod = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=7, minimum_probability=0.0)\n",
    "print \"training lsi...\"\n",
    "lsi_mod = gensim.models.lsimodel.LsiModel(corpus, id2word=dictionary, num_topics=100)\n",
    "print \"training word2vec...\"\n",
    "w2v_mod = gensim.models.Word2Vec(min_count=5, sg=5)\n",
    "sentences = [tokenize(x) for x in so_dat_main['bodyString'].tolist()]\n",
    "w2v_mod.build_vocab(sentences )\n",
    "w2v_mod.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# do left join with labels.....\n",
    "dat_combine = pd.merge(so_dat_main, label_dat)\n",
    "\n",
    "# basically perform negative sampling to find weights to optimize these two cases....\n",
    "\n",
    "# do stuff and output training dataset....(figure out how...)\n",
    "# will be adhoc for future...\n",
    "\n",
    "# train for recall..\n",
    "\n",
    "# get the dups...\n",
    "train = pd.read_csv(\"../SESE/cleaned/2016_link_dups_time_fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_query_all(single, docs, dictionary,\n",
    "              lsi_mod, lda_mod, w2v_mod, prefix=\"\"):\n",
    "    \"\"\"takes in two documents and computes similarity between\n",
    "    both based on the models above, with all equal weights\"\"\"\n",
    "    \n",
    "    sim_vec = {'lsi': sim_all_lsi(single, docs, lsi_mod, dictionary).flatten().tolist(),\n",
    "               'lda': sim_all_lda(single, docs, lda_mod, dictionary).flatten().tolist(), \n",
    "               'w2v': sim_all_w2v(single, docs, w2v_mod).flatten().tolist(), \n",
    "               'doc': sim_all(single, docs, dictionary).flatten().tolist()}\n",
    "    df = pd.DataFrame(sim_vec)\n",
    "    df.columns = [x+prefix for x in df.columns]\n",
    "    return df\n",
    "\n",
    "def sim_stackoverflow(single_dict, docs_df, columns, dictionary, \n",
    "                      lsi_mod, lda_mod, w2v_mod):\n",
    "    \"\"\"\n",
    "    single_dict is a dictionary...\n",
    "    \n",
    "    docs_df is dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #pd.concat([df1, df4], axis=1)\n",
    "    if columns is None:\n",
    "        columns = {'title': 'title', \n",
    "                   'body': 'bodyString', \n",
    "                   'tag': 'tagsString'}\n",
    "    #print columns\n",
    "    body_sim = sim_query_all(single_dict[columns['body']], docs_df[columns['body']].tolist(), \n",
    "                             dictionary, lsi_mod, lda_mod, w2v_mod, \"_body\")\n",
    "    title_sim = sim_query_all(single_dict[columns['title']], docs_df[columns['title']].tolist(), \n",
    "                             dictionary, lsi_mod, lda_mod, w2v_mod, \"_title\")\n",
    "    tag_sim = sim_query_all(single_dict[columns['tag']], docs_df[columns['tag']].tolist(), \n",
    "                             dictionary, lsi_mod, lda_mod, w2v_mod, \"_tag\")\n",
    "    \n",
    "    full_df = pd.concat([body_sim, title_sim, tag_sim], axis=1)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>lda_body</th>\n",
       "      <th>lsi_body</th>\n",
       "      <th>w2v_body</th>\n",
       "      <th>doc_title</th>\n",
       "      <th>lda_title</th>\n",
       "      <th>lsi_title</th>\n",
       "      <th>w2v_title</th>\n",
       "      <th>doc_tag</th>\n",
       "      <th>lda_tag</th>\n",
       "      <th>lsi_tag</th>\n",
       "      <th>w2v_tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "      <td>62499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.107023</td>\n",
       "      <td>0.444927</td>\n",
       "      <td>0.154371</td>\n",
       "      <td>0.893361</td>\n",
       "      <td>0.012779</td>\n",
       "      <td>0.263792</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>0.742113</td>\n",
       "      <td>0.095002</td>\n",
       "      <td>0.287191</td>\n",
       "      <td>0.158678</td>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.020320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.108180</td>\n",
       "      <td>0.271456</td>\n",
       "      <td>0.133280</td>\n",
       "      <td>0.046095</td>\n",
       "      <td>0.081008</td>\n",
       "      <td>0.327050</td>\n",
       "      <td>0.121812</td>\n",
       "      <td>0.098458</td>\n",
       "      <td>0.183626</td>\n",
       "      <td>0.287926</td>\n",
       "      <td>0.283465</td>\n",
       "      <td>0.169153</td>\n",
       "      <td>0.141095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>-0.055349</td>\n",
       "      <td>0.673672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064611</td>\n",
       "      <td>-0.087551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050143</td>\n",
       "      <td>-0.119497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.201474</td>\n",
       "      <td>0.057873</td>\n",
       "      <td>0.868851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087497</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>0.701649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080150</td>\n",
       "      <td>0.015719</td>\n",
       "      <td>0.845562</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>0.143518</td>\n",
       "      <td>0.891719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100756</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.740396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103309</td>\n",
       "      <td>0.051561</td>\n",
       "      <td>0.878157</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.154369</td>\n",
       "      <td>0.626433</td>\n",
       "      <td>0.211787</td>\n",
       "      <td>0.927838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165092</td>\n",
       "      <td>0.062924</td>\n",
       "      <td>0.802910</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.648507</td>\n",
       "      <td>0.076038</td>\n",
       "      <td>0.917434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc_body      lda_body      lsi_body      w2v_body     doc_title  \\\n",
       "count  62499.000000  62499.000000  62499.000000  62499.000000  62499.000000   \n",
       "mean       0.107023      0.444927      0.154371      0.893361      0.012779   \n",
       "std        0.108180      0.271456      0.133280      0.046095      0.081008   \n",
       "min        0.000000      0.003646     -0.055349      0.673672      0.000000   \n",
       "25%        0.029019      0.201474      0.057873      0.868851      0.000000   \n",
       "50%        0.086103      0.525125      0.143518      0.891719      0.000000   \n",
       "75%        0.154369      0.626433      0.211787      0.927838      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          lda_title     lsi_title     w2v_title       doc_tag       lda_tag  \\\n",
       "count  62499.000000  62499.000000  62499.000000  62499.000000  62499.000000   \n",
       "mean       0.263792      0.033261      0.742113      0.095002      0.287191   \n",
       "std        0.327050      0.121812      0.098458      0.183626      0.287926   \n",
       "min        0.064611     -0.087551      0.000000      0.000000      0.050143   \n",
       "25%        0.087497     -0.017045      0.701649      0.000000      0.080150   \n",
       "50%        0.100756      0.009868      0.740396      0.000000      0.103309   \n",
       "75%        0.165092      0.062924      0.802910      0.117851      0.648507   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            lsi_tag       w2v_tag         label  \n",
       "count  62499.000000  62499.000000  62499.000000  \n",
       "mean       0.158678      0.843477      0.020320  \n",
       "std        0.283465      0.169153      0.141095  \n",
       "min       -0.119497      0.000000      0.000000  \n",
       "25%        0.015719      0.845562      0.000000  \n",
       "50%        0.051561      0.878157      0.000000  \n",
       "75%        0.076038      0.917434      0.000000  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\n",
    "n_obs = 250\n",
    "f = FloatProgress(min=0, max=n_obs-1)\n",
    "display(f)\n",
    "\n",
    "train_subset = train.iloc[:250]\n",
    "train_labels = train_subset[['id', 'did']]\n",
    "train_labels.loc[:, 'label'] = 1\n",
    "\n",
    "m_ids = sorted(train_subset['id'].tolist(), key=lambda x: int(x))\n",
    "d_ids = sorted(train_subset['did'].tolist(), key=lambda x: int(x))\n",
    "\n",
    "ddict = {'title': 'dtitle', \n",
    "        'body': 'dbodyString', \n",
    "        'tag': 'dtagsString'}\n",
    "    \n",
    "train_feats = []\n",
    "\n",
    "for idx, m_id in enumerate(m_ids):\n",
    "    f.value = idx\n",
    "    train_temp = train_subset[train_subset['id'].astype(int) <= int(m_id)]\n",
    "    # restack dataframe...\n",
    "    dtrain_temp = train_temp[['dbodyString', 'dtagsString', 'dtitle', 'did']]\n",
    "    dtrain_temp.columns = [x[1:] for x in dtrain_temp.columns]\n",
    "    train_temp = train_temp[['id', 'title', 'bodyString', 'tagsString']]\n",
    "    train_temp = pd.concat([train_temp, dtrain_temp])\n",
    "    train_temp = train_temp[train_temp['id'] != m_id]\n",
    "    single_doc = train_subset[train_subset['id'] == m_ids[0]].to_dict(orient=\"records\")[0]\n",
    "    temp_feats = sim_stackoverflow(single_doc, train_temp, None, dictionary,\n",
    "              lsi_mod, lda_mod, w2v_mod)\n",
    "    # input column and dup col - to infer id. \n",
    "    temp_feats.loc[:, 'id'] = m_id\n",
    "    temp_feats.loc[:, 'did'] = train_temp['id'].tolist() \n",
    "    train_feats.append(temp_feats)\n",
    "    \n",
    "feature_df = pd.merge(pd.concat(train_feats), train_labels, on=['id', 'did'], how='left').drop_duplicates()\n",
    "feature_df['label'] = feature_df['label'].fillna(0)\n",
    "feature_df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df.to_pickle(\"feature_df_lda_final7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature_df = pd.read_pickle(\"feature.df.pkl\") # where the hell did this one come from??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feature_df[[u'doc_body', u'lda_body', u'lsi_body', u'w2v_body', u'doc_title',\n",
    "       u'lda_title', u'lsi_title', u'w2v_title', u'doc_tag', u'lda_tag',\n",
    "       u'lsi_tag', u'w2v_tag']].as_matrix()\n",
    "       \n",
    "Y = feature_df[['label']].as_matrix().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1fb57ba09f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mmin_impurity_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-07\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf = SGDClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=2, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b9ef9f68852a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;31m#grid_search.predict(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf.fit(X, Y)\n",
    "#grid_search.predict(X)\n",
    "\n",
    "print(confusion_matrix(Y, rf.predict(X)))\n",
    "print(recall_score(Y, rf.predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61228     1]\n",
      " [  299   971]]\n",
      "0.764566929134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X, Y)\n",
    "#grid_search.predict(X)\n",
    "\n",
    "print(confusion_matrix(Y, clf.predict(X)))\n",
    "print(recall_score(Y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter loss for estimator Perceptron. Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e703bf6655de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[1;31m#grid_search.predict(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 for train, test in cv)\n\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    289\u001b[0m                                      \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                      \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                                      (key, self.__class__.__name__))\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter loss for estimator Perceptron. Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# randomforest classifier\n",
    "clf = SGDClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "# use a full grid over all parameters\n",
    "\n",
    "param_grid = { \n",
    "    'loss': ('log', 'hinge'),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00001, 0.000001]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(estimator=clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=recall_scorer)\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(X, Y)\n",
    "#grid_search.predict(X)\n",
    "\n",
    "print(confusion_matrix(Y, grid_search.predict(X)))\n",
    "print(recall_score(Y, grid_search.predict(X)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# build tree to see important feats?\n",
    "feat_importance = grid_search.estimator.fit(X,Y).feature_importances_\n",
    "\n",
    "feat_df = pd.DataFrame({\n",
    "    'importances': feat_importance,\n",
    "    'names': [u'doc_body', u'lda_body', u'lsi_body', u'w2v_body', u'doc_title',\n",
    "       u'lda_title', u'lsi_title', u'w2v_title', u'doc_tag', u'lda_tag',\n",
    "       u'lsi_tag', u'w2v_tag']\n",
    "                        })\n",
    "feat_df = feat_df.sort(['importances'], ascending=False)\n",
    "feat_df.plot.bar(x=\"names\", y=\"importances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.estimator\n",
    "\n",
    "\"\"\"\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=2, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "6aa9f49c86384506980e689525802dbc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
